{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS AND FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_preprocessing import combine_image_folders, erase_double_images, train_test\n",
    "\n",
    "import functions_licenseplate as fl\n",
    "\n",
    "import functions_recognition as r\n",
    "\n",
    "import SVC as svc\n",
    "\n",
    "import CNN as cnn\n",
    "\n",
    "import API_car_model as api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESSING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder created: G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_IMAGES\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"source_folders = [\n",
    "    \"G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/Images/FOTOS MERI\",\n",
    "    \"G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/Images/FOTOS\",\n",
    "    \"G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/Images/FOTOS LARA\",\n",
    "    \"G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/Images/Images (CV)/Frontal\",\n",
    "    \"G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/Images/Images (CV)/Lateral\"\n",
    "]\n",
    "\n",
    "destination_folder = 'G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_IMAGES'\n",
    "combine_image_folders(source_folders, destination_folder) #ALREADY CREATED\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_IMAGES\\8970GZR (1).jpg\n",
      "Deleted: G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_IMAGES\\7122FYJ (1).jpg\n",
      "Deleted: G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_IMAGES\\2748LKK (1).jpg\n",
      "Deleted: G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_IMAGES\\0085LND (1).jpg\n",
      "Deleted: G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_IMAGES\\1139LJX (1).jpg\n",
      "Deleted: G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_IMAGES\\2375KFD (1).jpg\n",
      "Deleted: G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_IMAGES\\4634JKH (1).jpg\n",
      "Deleted: G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_IMAGES\\4346HMW (1).jpg\n",
      "Deleted: G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_IMAGES\\8033MLP (1).jpg\n",
      "Deleted: G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_IMAGES\\4812GTX (1).jpg\n",
      "Deleted: G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_IMAGES\\3214LCL (1).jpg\n",
      "Deleted: G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_IMAGES\\7911LYX (1).jpg\n",
      "Deleted: G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_IMAGES\\1258GBP (1).jpg\n",
      "Deleted: G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_IMAGES\\1818GZL (1).jpg\n",
      "Deleted: G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_IMAGES\\9455JKM (1).jpg\n",
      "Deleted: G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_IMAGES\\6445HNP (1).jpg\n",
      "Deleted: G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_IMAGES\\6011HHV (2).jpg\n",
      "Deleted: G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_IMAGES\\9980GCB (1).jpg\n",
      "Deleted: G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_IMAGES\\1556DXM (1).jpg\n",
      "Deleted: G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_IMAGES\\6011HHV (1).jpg\n",
      "Deleted: G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_IMAGES\\1681LJT (1).jpg\n",
      "Deleted: G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_IMAGES\\2552HGF (1).jpg\n",
      "Deleted: G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_IMAGES\\4077LKM (1).jpg\n",
      "Deleted: G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_IMAGES\\4960GXC (1).jpg\n",
      "Deleted: G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_IMAGES\\5498HKM (1).jpg\n",
      "Deleted: G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_IMAGES\\5753GPV (1).jpg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"folder_path = 'G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_IMAGES'\n",
    "erase_double_images(folder_path)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split complete: 144 training files, 72 testing files, 24 validation files.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"source_folder = 'G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_IMAGES'  \n",
    "train_folder = 'G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_trainset'    \n",
    "test_folder = 'G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_testset'     \n",
    "val_folder = 'G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_validationset'\n",
    "# Call the train_test function to perform the split\n",
    "train_test(source_folder, train_folder, test_folder, val_folder)\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DETECTION LICENSE PLATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CROPPING USING YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"image_folder_2 = 'G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_trainset'\n",
    "cropped_plates_train = fl.boundingbox(image_folder_2)#dictionary name plate (sequence) + croppedd image\n",
    "image_folder_3 = 'G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_testset'\n",
    "cropped_plates_train = fl.boundingbox(image_folder_3)#dictionary name plate (sequence) + croppedd image\n",
    "image_folder_4 = 'G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_validationset'\n",
    "cropped_plates_train = fl.boundingbox(image_folder_4)#dictionary name plate (sequence) + croppedd image\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"save_folder = 'G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_trainset_croppedimages'\n",
    "fl.display_and_save_cropped_plates(cropped_plates_train, save_folder)\n",
    "save_folder = 'G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_testset_croppedimages'\n",
    "fl.display_and_save_cropped_plates(cropped_plates_train, save_folder)\n",
    "save_folder = 'G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_validationset_croppedimages'\n",
    "fl.display_and_save_cropped_plates(cropped_plates_train, save_folder)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING MODELS (character detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path_lara = 'G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/Dataset Characters'\n",
    "accuracy, clf, scaler, label_encoder = svc.train_svm_and_get_accuracy(base_path_lara)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  \n",
    "    transforms.Resize((28, 28)),                 \n",
    "    transforms.ToTensor(),                        \n",
    "    transforms.Normalize((0.5,), (0.5,))         \n",
    "])\n",
    "\n",
    "dataset = ImageFolder(root= base_path_lara, transform=transform)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "#print(f\"Classes: {dataset.classes}\")\n",
    "\n",
    "num_classes = len(dataset.classes)\n",
    "model = cnn.CNNModel(num_classes)\n",
    "\n",
    "criterion = cnn.nn.CrossEntropyLoss() \n",
    "optimizer = cnn.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model.to(cnn.device)\n",
    "\n",
    "cnn.train_model(model, train_loader, criterion, optimizer, num_epochs=30)\n",
    "cnn.evaluate_model(model,test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_lara = 'G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_trainset_croppedimages'\n",
    "\n",
    "for image_file in os.listdir(pc_lara):\n",
    "        if image_file.endswith(('.jpg')):  # Ensure we're processing image files only\n",
    "            image_path = os.path.join(pc_lara, image_file)\n",
    "            image = cv2.imread(image_path)\n",
    "            car = image.copy()\n",
    "            \n",
    "            #SEGMENTATION CHARACTERS------------------------------------------\n",
    "            #METHOD 1\n",
    "            m1_chars = r.segment_characters(image)\n",
    "            r.visualize_char(m1_chars)\n",
    "\n",
    "            #METHOD 2\n",
    "            upscaled_license_plate, m2_chars = r.OCR_image(license_plate = image, t = 180 ,min_h = 80, min_w = 20, min_ar = 0.2, max_ar = 1.4, area = 6000)\n",
    "\n",
    "            #Choose the best method\n",
    "            best_char = r.best_segmentation_method(m1_chars, m2_chars)\n",
    "\n",
    "            #SAVE CHARACTERS IF WELL-SEGMENTED TO INCREASE THE DATASET (only trainset images)\n",
    "            #for i in range(len(characters)):\n",
    "            #save the files to expand the dataset\n",
    "            #output_path = os.path.join(\"G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/Dataset Characters\", f'caracter_{i}.png')\n",
    "            #cv2.imwrite(output_path, characters[i])\n",
    "\n",
    "\n",
    "            #PREDICTION MODELS------------------------------------------\n",
    "            plate_sol = svc.test_preprocessed_images_with_plot(clf, scaler, best_char, label_encoder)\n",
    "\n",
    "            label_encoder = LabelEncoder()\n",
    "            label_encoder.fit(dataset.classes)  \n",
    "            predicted_plate = cnn.predict_characters(model, best_char, label_encoder)\n",
    "\n",
    "            license_plate_text = r.easy_ocr_method(upscaled_license_plate)\n",
    "\n",
    "            spain = input(\"Is it an Spanish plate?: \")\n",
    "\n",
    "            if spain == \"Y\":\n",
    "                filter_plate_svc = r.filter_spain_plates(plate_sol)\n",
    "                filter_plate_cnn = r.filter_spain_plates(predicted_plate)\n",
    "                filter_plate_ocr = r.filter_spain_plates(license_plate_text)\n",
    "\n",
    "                fig, axes = plt.subplots(1, 2, figsize=(10, 5))  \n",
    "                \n",
    "                axes[0].imshow(car, cmap='gray')\n",
    "                axes[0].set_title(f\"Predicted Label (SVM) - TRAIN: {plate_sol}\\nFilter Applied - TRAIN: {filter_plate_svc}\")\n",
    "                axes[0].axis('off')  \n",
    "\n",
    "                axes[1].imshow(car, cmap='gray')\n",
    "                axes[1].set_title(f\"Predicted Label (CNN) - TRAIN: {predicted_plate}\\nFilter Applied - TRAIN: {filter_plate_cnn}\")\n",
    "                axes[1].axis('off')  \n",
    "\n",
    "                axes[2].imshow(car, cmap='gray')\n",
    "                axes[2].set_title(f\"Predicted Label (EasyOCR) - TRAIN: {license_plate_text}\\nFilter Applied - TRAIN: {filter_plate_ocr}\")\n",
    "                axes[3].axis('off') \n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "            else:\n",
    "                fig, axes = plt.subplots(1, 2, figsize=(10, 5))  \n",
    "                \n",
    "                axes[0].imshow(car, cmap='gray')\n",
    "                axes[0].set_title(f\"Predicted Label (SVM) - TRAIN: {plate_sol}\")\n",
    "                axes[0].axis('off')  \n",
    "\n",
    "                axes[1].imshow(car, cmap='gray')\n",
    "                axes[1].set_title(f\"Predicted Label (CNN) - TRAIN: {predicted_plate}\")\n",
    "                axes[1].axis('off')  \n",
    "\n",
    "                axes[2].imshow(car, cmap='gray')\n",
    "                axes[2].set_title(f\"Predicted Label (EasyOCR) - TRAIN: {license_plate_text}\")\n",
    "                axes[3].axis('off') \n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_lara = 'G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_testset_croppedimages'\n",
    "\n",
    "for image_file in os.listdir(pc_lara):\n",
    "        if image_file.endswith(('.jpg')):  # Ensure we're processing image files only\n",
    "            image_path = os.path.join(pc_lara, image_file)\n",
    "            image = cv2.imread(image_path)\n",
    "            car = image.copy()\n",
    "            \n",
    "            #SEGMENTATION CHARACTERS------------------------------------------\n",
    "            #METHOD 1\n",
    "            m1_chars = r.segment_characters(image)\n",
    "            r.visualize_char(m1_chars)\n",
    "\n",
    "            #METHOD 2\n",
    "            upscaled_license_plate, m2_chars = r.OCR_image(license_plate = image, t = 180 ,min_h = 80, min_w = 20, min_ar = 0.2, max_ar = 1.4, area = 6000)\n",
    "\n",
    "            #Choose the best method\n",
    "            best_char = r.best_segmentation_method(m1_chars, m2_chars)\n",
    "\n",
    "            #PREDICTION MODELS------------------------------------------\n",
    "            plate_sol = svc.test_preprocessed_images_with_plot(clf, scaler, best_char, label_encoder)\n",
    "\n",
    "            label_encoder = LabelEncoder()\n",
    "            label_encoder.fit(dataset.classes)  \n",
    "            predicted_plate = cnn.predict_characters(model, best_char, label_encoder)\n",
    "\n",
    "            license_plate_text = r.easy_ocr_method(upscaled_license_plate)\n",
    "\n",
    "            spain = input(\"Is it an Spanish plate?: \")\n",
    "\n",
    "            if spain == \"Y\":\n",
    "                filter_plate_svc = r.filter_spain_plates(plate_sol)\n",
    "                filter_plate_cnn = r.filter_spain_plates(predicted_plate)\n",
    "                filter_plate_ocr = r.filter_spain_plates(license_plate_text)\n",
    "\n",
    "                fig, axes = plt.subplots(1, 2, figsize=(10, 5))  \n",
    "                \n",
    "                axes[0].imshow(car, cmap='gray')\n",
    "                axes[0].set_title(f\"Predicted Label (SVM) - TEST: {plate_sol}\\nFilter Applied - TEST: {filter_plate_svc}\")\n",
    "                axes[0].axis('off')  \n",
    "\n",
    "                axes[1].imshow(car, cmap='gray')\n",
    "                axes[1].set_title(f\"Predicted Label (CNN) - TEST: {predicted_plate}\\nFilter Applied - TEST: {filter_plate_cnn}\")\n",
    "                axes[1].axis('off')  \n",
    "\n",
    "                axes[2].imshow(car, cmap='gray')\n",
    "                axes[2].set_title(f\"Predicted Label (EasyOCR) - TEST: {license_plate_text}\\nFilter Applied - TEST: {filter_plate_ocr}\")\n",
    "                axes[3].axis('off') \n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "            else:\n",
    "                fig, axes = plt.subplots(1, 2, figsize=(10, 5))  \n",
    "                \n",
    "                axes[0].imshow(car, cmap='gray')\n",
    "                axes[0].set_title(f\"Predicted Label (SVM) - TEST: {plate_sol}\")\n",
    "                axes[0].axis('off')  \n",
    "\n",
    "                axes[1].imshow(car, cmap='gray')\n",
    "                axes[1].set_title(f\"Predicted Label (CNN) - TEST: {predicted_plate}\")\n",
    "                axes[1].axis('off')  \n",
    "\n",
    "                axes[2].imshow(car, cmap='gray')\n",
    "                axes[2].set_title(f\"Predicted Label (EasyOCR) - TEST: {license_plate_text}\")\n",
    "                axes[3].axis('off') \n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VALIDATION RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_lara = 'G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/GITHUB_validationset_croppedimages'\n",
    "\n",
    "for image_file in os.listdir(pc_lara):\n",
    "        if image_file.endswith(('.jpg')):  # Ensure we're processing image files only\n",
    "            image_path = os.path.join(pc_lara, image_file)\n",
    "            image = cv2.imread(image_path)\n",
    "            car = image.copy()\n",
    "            \n",
    "            #SEGMENTATION CHARACTERS------------------------------------------\n",
    "            #METHOD 1\n",
    "            m1_chars = r.segment_characters(image)\n",
    "            r.visualize_char(m1_chars)\n",
    "\n",
    "            #METHOD 2\n",
    "            upscaled_license_plate, m2_chars = r.OCR_image(license_plate = image, t = 180 ,min_h = 80, min_w = 20, min_ar = 0.2, max_ar = 1.4, area = 6000)\n",
    "\n",
    "            #Choose the best method\n",
    "            best_char = r.best_segmentation_method(m1_chars, m2_chars)\n",
    "\n",
    "            #PREDICTION MODELS------------------------------------------\n",
    "            plate_sol = svc.test_preprocessed_images_with_plot(clf, scaler, best_char, label_encoder)\n",
    "\n",
    "            label_encoder = LabelEncoder()\n",
    "            label_encoder.fit(dataset.classes)  \n",
    "            predicted_plate = cnn.predict_characters(model, best_char, label_encoder)\n",
    "\n",
    "            license_plate_text = r.easy_ocr_method(upscaled_license_plate)\n",
    "\n",
    "            spain = input(\"Is it an Spanish plate?: \")\n",
    "\n",
    "            if spain == \"Y\":\n",
    "                filter_plate_svc = r.filter_spain_plates(plate_sol)\n",
    "                filter_plate_cnn = r.filter_spain_plates(predicted_plate)\n",
    "                filter_plate_ocr = r.filter_spain_plates(license_plate_text)\n",
    "\n",
    "                fig, axes = plt.subplots(1, 2, figsize=(10, 5))  \n",
    "                \n",
    "                axes[0].imshow(car, cmap='gray')\n",
    "                axes[0].set_title(f\"Predicted Label (SVM) - VALIDATION: {plate_sol}\\nFilter Applied - VALIDATION: {filter_plate_svc}\")\n",
    "                axes[0].axis('off')  \n",
    "\n",
    "                axes[1].imshow(car, cmap='gray')\n",
    "                axes[1].set_title(f\"Predicted Label (CNN) - VALIDATION: {predicted_plate}\\nFilter Applied - VALIDATION: {filter_plate_cnn}\")\n",
    "                axes[1].axis('off')  \n",
    "\n",
    "                axes[2].imshow(car, cmap='gray')\n",
    "                axes[2].set_title(f\"Predicted Label (EasyOCR) - VALIDATION: {license_plate_text}\\nFilter Applied - VALIDATION: {filter_plate_ocr}\")\n",
    "                axes[3].axis('off') \n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "            else:\n",
    "                fig, axes = plt.subplots(1, 2, figsize=(10, 5))  \n",
    "                \n",
    "                axes[0].imshow(car, cmap='gray')\n",
    "                axes[0].set_title(f\"Predicted Label (SVM) - VALIDATION: {plate_sol}\")\n",
    "                axes[0].axis('off')  \n",
    "\n",
    "                axes[1].imshow(car, cmap='gray')\n",
    "                axes[1].set_title(f\"Predicted Label (CNN) - VALIDATION: {predicted_plate}\")\n",
    "                axes[1].axis('off')  \n",
    "\n",
    "                axes[2].imshow(car, cmap='gray')\n",
    "                axes[2].set_title(f\"Predicted Label (EasyOCR) - VALIDATION: {license_plate_text}\")\n",
    "                axes[3].axis('off') \n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATING MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD INFO MERI:) (GRAFS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATE: 200\n",
      "RESPONSE: <?xml version=\"1.0\" encoding=\"utf-8\"?><soap:Envelope xmlns:soap=\"http://schemas.xmlsoap.org/soap/envelope/\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\"><soap:Body><CheckSpainResponse xmlns=\"http://regcheck.org.uk\"><CheckSpainResult><vehicleJson>{\n",
      "  \"Description\": \"CITROEN C3\",\n",
      "  \"CarMake\": {\n",
      "    \"CurrentTextValue\": \"CITROEN\"\n",
      "  },\n",
      "  \"CarModel\": {\n",
      "    \"CurrentTextValue\": \"C3\"\n",
      "  },\n",
      "  \"MakeDescription\": {\n",
      "    \"CurrentTextValue\": \"CITROEN\"\n",
      "  },\n",
      "  \"ModelDescription\": {\n",
      "    \"CurrentTextValue\": \"C3\"\n",
      "  },\n",
      "  \"EngineSize\": \"1199\",\n",
      "  \"VehicleIdentificationNumber\": null,\n",
      "  \"RegistrationYear\": \"2023\",\n",
      "  \"RegistrationDate\": \"15/06/2023\",\n",
      "  \"Variation\": \"1.2 PURETECH 83 FEEL\",\n",
      "  \"Seats\": null,\n",
      "  \"VariantType\": \"Gasolina 1199 cc 5 puertas\",\n",
      "  \"VehicleType\": \"Car\",\n",
      "  \"Fuel\": \"Gasolina\",\n",
      "  \"IndicativePrice\": null,\n",
      "  \"Doors\": \"5\",\n",
      "  \"AllTerain\": null,\n",
      "  \"KType\": null,\n",
      "  \"ImageUrl\": \"http://matriculaapi.com/image.aspx/@Q0lUUk9FTiBDMw==\",\n",
      "  \"DynamicPower\": \"83.0\",\n",
      "  \"Stolen\": null\n",
      "}</vehicleJson><vehicleData><Description>CITROEN C3</Description><RegistrationYear>2023</RegistrationYear><CarMake><CurrentTextValue>CITROEN</CurrentTextValue></CarMake><CarModel>C3</CarModel><EngineSize><CurrentTextValue>1199</CurrentTextValue></EngineSize></vehicleData></CheckSpainResult></CheckSpainResponse></soap:Body></soap:Envelope>\n"
     ]
    }
   ],
   "source": [
    "#api.api_car_model(predicted_plate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COUNTER CHARACTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to folder_counts.csv\n"
     ]
    }
   ],
   "source": [
    "path = \"G:/Mi unidad/LICENSE_PLATES_RECOGITION_L&V/Dataset Characters\"\n",
    "output_file = \"folder_counts.csv\"\n",
    "r.count_files_in_folders(path, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
